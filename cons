#!/usr/bin/env python

# GY171017

''' cons: intelligent consensus formation '''


from __future__ import print_function  # Py2
from argparse import ArgumentParser, FileType, SUPPRESS
from collections import defaultdict as dd, namedtuple
from bisect import insort
from math import ceil
from signal import signal, SIGPIPE, SIG_DFL
from sys import stdin, stdout, stderr


# Globals #####################################################################


signal(SIGPIPE, SIG_DFL)  # Gracefully handle downstream PIPE closure

# data structures
fastarecord = namedtuple('fastarecord', ['seqid', 'seq'])
depthrange = namedtuple('depthrange', ['start', 'stop', 'depth'])

iupac_codes = {
    'AG': 'R', 'CT': 'Y', 'CG': 'S', 'AT': 'W', 'GT': 'K', 'AC': 'M',
    'CGT': 'B', 'AGT': 'D', 'ACT': 'H', 'ACG': 'V',
    'ACGT': 'N', '': 'N'}


# Classes #####################################################################


class FastaReader(object):
    ''' A class for reading FASTA records'''

    def __init__(self, inputstream):
        self._fileobj = inputstream
        self._buffer = self._fileobj.readline()

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        pass

    def __iter__(self):
        return self

    def __next__(self):
        while self._buffer and not self._buffer.startswith('>'):
            self._buffer = self._fileobj.readline()
        if not self._buffer:
            raise StopIteration
        seqid = self._buffer[1:].strip().split(' ')[0]
        seqlines = []
        self._buffer = self._fileobj.readline()
        while self._buffer and not self._buffer.startswith('>'):
            seqlines.append(self._buffer.strip())
            self._buffer = self._fileobj.readline()
        return fastarecord(seqid, ''.join(seqlines).upper())

    next = __next__


class RunningMedian(object):

    def __init__(self):
        self._lows = []
        self._highs = []

    def __call__(self, n):
        n = float(n)
        if not self._lows or n < max(self._lows):
            insort(self._lows, n)
            if len(self._lows) - len(self._highs) > 1:
                self._highs = [self._lows.pop()] + self._highs
        else:
            insort(self._highs, n)
            if len(self._highs) - len(self._lows) > 1:
                self._lows.append(self._highs.pop(0))
        return self.median()

    def median(self):
        if len(self._lows) == len(self._highs):
            return (self._lows[-1] + self._highs[0]) / 2.0
        elif len(self._lows) > len(self._highs):
            return self._lows[-1]
        # else implied
        return self._highs[0]


# Functions ###################################################################


def median(x):
    ''' Return the median '''
    x = sorted(x)
    if len(x) & 1:
        return float(x[len(x)//2])
    # else implied
    return sum(x[len(x)//2-1:len(x)//2+1]) / 2.0


def consensus_base(base, iupac=False):
    ''' Decide the consensus at a base position '''

    try:
        del(base['-'])
    except KeyError:
        pass
    if not base:
        return '-'  # Return gap-only
    elif len(base) == 1:
        return base.popitem()[0]  # Return unambiguous
    nts = sorted([(k, v) for k, v in base.items()],
        key=lambda x: x[1], reverse=True)
    if not iupac:
        nts = [nt for nt in nts if nt[1] == nts[0][1]]
        if len(nts) == 1:
            return nts[0][0]  # Return majority
        return 'N'  # Return majority indecision
    else:
        nts = [nt for nt in nts if nt[1] >= float(nts[0][1]) / 2]
        if len(nts) == 1:
            return nts[0][0]  # Return majority
        return iupac_codes[''.join(sorted([nt[0] for nt in nts if nt[0] in 'ATCG']))]  # Return iupac indecision


def grouper(iterable, k):
    ''' Yield a memory-mapped iterable in chunks of `k` '''
    for i in range(int(ceil(float(len(iterable)) / k))):  # Py2
        yield iterable[i*k:i*k+k]


def printseq(seqid, seq, quals='', fileobj=stdout):
    ''' Appropraitely prints a sequence '''
    if quals:
        print('@{}\n{}\n+\n{}'.format(seqid, seq, quals), file=fileobj)
    elif 'wrap' not in args:
        print('>{}\n{}'.format(seqid, seq), file=fileobj)
    else:
        print('>{}'.format(seqid), file=fileobj)
        for chunk in grouper(seq, args.wrap):
            print(chunk, file=fileobj)


###############################################################################


if __name__ == '__main__':

    parser = ArgumentParser(
        description='cons: intelligent consensus formation',
        argument_default=SUPPRESS)
    parser.add_argument(
        'input', nargs='?', type=FileType('r'), default=stdin,
        help='Input FASTA alignment file (use "-" or leave blank for stdin)')
    parser.add_argument(
        '-n', '--name', required=True,
        help='Sequence identifier for the consensus')
    parser.add_argument(
        '-a', '--ambig', nargs='?', const=0.5, type=float,
        help='Use IUPAC ambiguity codes to represent positions where any base \
        is >= `a` fold as frequent as the most frequent nucleotide at the \
        position (default %(const)s)')
    parser.add_argument(
        '-m', '--min', default=2, nargs='?', type=int,
        help='Only ever include sites >= depth `m` (default %(default)s)')
    parser.add_argument(
        '-g', '--glob', const=0.2, nargs='?', type=float,
        help='The per-site required alignment depth must be >= \
        max(`g`*totaldepth, `m`) (default %(const)s)')
    parser.add_argument(
        '-l', '--loc', const=0.5, nargs='?', type=float,
        help='The per-site required alignment depth is calculated in \
        comparison to its local region, and must be >= \
        max(`l`*localdepth, `m`) (default %(const)s). When combined with `g`, \
        the calculated local depth must also be >= `g`*totaldepth')
    parser.add_argument(
        '-s', '--smooth', default=50, nargs='?', type=float,
        help='Minimum size (nts) of local areas for use with `-l` \
        (default %(default)s)')
    parser.add_argument(
        '-w', '--wrap', nargs='?', type=int, const=80,
        help='Wrap lines at `w` when outputting FASTA (default %(const)s when \
        supplied alone)')
    parser.add_argument(
        '--retaingaps', action='store_true',
        help='Retain gap characters in consensus (useful for comparing to \
        original alignment)')
    parser.add_argument(
        '--changepoints', action='store_true',
        help='Print the changepoints detected with `-l` to stderr (start, \
        stop, median depth)')
    args = parser.parse_args()

    with FastaReader(args.input) as F:
        for i, record in enumerate(F):
            if not i:
                aln = [dd(int) for _ in range(len(record.seq))]
            for j, base in enumerate(record.seq):
                aln[j][base] += 1

    totaldepth = i + 1

    if not 'loc' in args:

        depth_req = totaldepth - max(args.min,
            ceil(args.glob * totaldepth) if 'glob' in args else 0)
        cons = [consensus_base(base, args.ambig if 'ambig' in args else False)
            if base.get('-', 0) <= depth_req else '-' for base in aln]

    else:

        depths = [sum(v for k, v in base.items() if k != '-') for base in aln]
        changes, m = [], 0
        med = RunningMedian()
        for i, depth in enumerate(depths):
            # Changepoint if depth differs from the running median +- slop
            if not m * 0.9 < depth < m * 1.1:
                changes.append(i)
                # Reset the running median
                med = RunningMedian()
            m = med(depth)
        changes.append(len(aln))

        # Smooth the changepoints
        _changes = [depthrange(changes[0], changes[1],
            median(depths[changes[0]:changes[1]]))]
        for i, c in enumerate(changes[1:-1], 1):
            region_depth = median(depths[c:changes[i+1]])
            # If the depths are equivalent, extend previous
            if _changes[-1].depth * 0.9 <= region_depth <= _changes[-1].depth * 1.1:
                _changes[-1] = _changes[-1]._replace(
                    stop=changes[i+1],
                    depth=median(depths[_changes[-1].start:changes[i+1]]))
            # Else if the depth decreases then filter on size
            elif region_depth < _changes[-1].depth and changes[i+1] - c < args.smooth:
                _changes[-1] = _changes[-1]._replace(
                    stop=changes[i+1],
                    depth=median(depths[_changes[-1].start:changes[i+1]]))
            # Else allow the changepoint
            else:
                _changes.append(depthrange(
                    c, changes[i+1], region_depth))
        changes = _changes

        if 'changepoints' in args:
            for c in changes:
                print(*c, file=stderr)

        cons = []
        for region in changes:
            if 'glob' in args and region.depth < totaldepth * args.glob:
                cons += ['-' for base in aln[region.start:region.stop]]
                continue
            # else implied
            depth_req = totaldepth - max(args.min, ceil(args.loc * region.depth))
            cons += [consensus_base(base, args.ambig if 'ambig' in args else False)
                if base.get('-', 0) <= depth_req else '-' for base in aln[region.start:region.stop]]

    if 'retaingaps' not in args:
        cons = [base for base in cons if base != '-']
    printseq(args.name, ''.join(cons))
