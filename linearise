#!/usr/bin/env python

# GY170801

''' linearise: FASTA <-> TSV conversion '''


from __future__ import print_function  # Py2
from argparse import ArgumentParser, FileType, SUPPRESS
from collections import namedtuple
from math import ceil
from signal import signal, SIGPIPE, SIG_DFL
from sys import stdin, stdout


# Globals #####################################################################


signal(SIGPIPE, SIG_DFL)  # Gracefully handle downstream PIPE closure

# data structures
seqrecord = namedtuple('seqrecord', ['seqid', 'seq', 'quals'])


# Classes #####################################################################


class MultiReader(object):
    ''' A class for reading FASTA/Q records '''

    def __init__(self, inputstream):
        self._fileobj = inputstream
        self._buffer = ' '

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        pass

    def __iter__(self):
        return self

    def __next__(self):
        while self._buffer and self._buffer[0] not in ('>', '@'):
            self._buffer = self._fileobj.readline()
        if not self._buffer:
            raise StopIteration
        if self._buffer[0] == ">":
            seqid = self._buffer[1:].strip()
            self._buffer = self._fileobj.readline()
            seqlines = []
            while self._buffer and self._buffer[0] not in ('>', '@'):
                seqlines.append(self._buffer.strip())
                self._buffer = self._fileobj.readline()
            return seqrecord(seqid, ''.join(seqlines).upper(), '')
        else:
            seqid = self._buffer[1:].strip()
            seq = self._fileobj.readline().strip().upper()
            self._fileobj.readline()
            quals = self._fileobj.readline().strip()
            self._buffer = self._fileobj.readline()
            return seqrecord(seqid, seq, quals)

    next = __next__  # Py2 compatibility


# Functions ###################################################################


def grouper(iterable, k):
    ''' Yield a memory-mapped iterable in chunks of `k` '''
    for i in range(int(ceil(float(len(iterable)) / k))):  # Py2
        yield iterable[i*k:i*k+k]


def printseq(record, fileobj=stdout):
    ''' Appropraitely prints a seqrecord or equivalent 2 or 3-item iterable '''
    if len(record) == 3 and record[2]:
        print('@{}\n{}\n+\n{}'.format(*record), file=fileobj)
    elif 'wrap' not in args:
        print('>{}\n{}'.format(record[0], record[1]), file=fileobj)
    else:
        print('>{}'.format(record[0]), file=fileobj)
        for chunk in grouper(record[1], args.wrap):
            print(chunk, file=fileobj)


###############################################################################


if __name__ == '__main__':

    parser = ArgumentParser(
        description='FASTA/Q <-> TSV conversion',
        epilog='Converts to and from a standardised 3 column \
        (ID \\t Seq \\t Qual) format. Linearised FASTA data will have no \
        entry in the third column and both two-column data and data where the \
        third column is empty will be re-interpreted as FASTA with `-v`.',
        argument_default=SUPPRESS)
    parser.add_argument(
        'input', nargs='*', type=FileType('r'), default=[stdin],
        help='Input file(s) (use "-" or leave blank for stdin)')
    parser.add_argument(
        '-v', '--inverse', action='store_true',
        help='Convert delimited lines back to FASTA/Q')
    parser.add_argument(
        '-w', '--wrap', nargs='?', type=int, const=80,
        help='Wrap lines at `w` when outputting FASTA (default %(const)s)')
    args = parser.parse_args()

    if 'inverse' not in args:
        for f in args.input:
            with MultiReader(f) as F:
                for record in F:
                    print('\t'.join(record))

    else:
        for f in args.input:
            for l in f:
                printseq(l.strip('\r\n').split('\t'))
