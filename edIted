#!/usr/bin/env python3

''' edIted: statistical comparison of RNA editing '''

import gzip
import logging
import re
from argparse import ArgumentParser, FileType
from collections import Counter
from functools import total_ordering
from itertools import chain
from math import log10, pow
from signal import signal, SIGPIPE, SIG_DFL
from sys import stdout
from typing import Any, Iterator, Tuple

import numpy as np
from scipy.stats import dirichlet


__author__ = 'George R Young'
__maintainer__ = 'George R Young'
__email__ = 'george.young@crick.ac.uk'
__version__ = '0.2'
__stamp__ = 'GY200709'
__status__ = 'Development'
__license__ = 'MIT license'


signal(SIGPIPE, SIG_DFL)  # Gracefully handle downstream PIPE closure
np.seterr(all='ignore')  # Silence numpy stderr warnings


# Globals #####################################################################


other_nts = {'A': 'CGT', 'C': 'AGT', 'G': 'ACT', 'T': 'ACG'}
indel_re = re.compile('[0-9]+')


# Classes #####################################################################


class Empty(object):
    ''' Dummy class to allow class creation without __init__ being called when
    copying UnstrandedPileup and StrandedPileup instances '''
    pass


@total_ordering
class UnstrandedPileup(object):
    ''' A class for holding per-base stranded mpileup data '''

    def __init__(self, mpileup: str) -> None:
        self.chrom, pos, self.ref, *self.mpileup = mpileup.strip().split('\t')
        self.pos = int(pos)

    def _parse(self) -> None:
        self.base_counts = {'A': 0, 'C': 0, 'G': 0, 'T': 0}
        self.base_probs = {'A': [], 'C': [], 'G': [], 'T': []}
        _, mapping, quals, *_ = self.mpileup
        i, j = 0, 0
        while i < len(mapping):
            if mapping[i] in '.,':
                self.base_counts[self.ref] += 1
                p = pow(10, -ord(quals[j]) / 10)
                self.base_probs[self.ref].append(1 - p)
                for b in other_nts[self.ref]:
                    self.base_probs[b].append(p / 3)
                i += 1
                j += 1
            elif mapping[i] in '<>*#':
                i += 1
                j += 1
            elif mapping[i] == '^':
                i += 2
            elif mapping[i] == '$':
                i += 1
            elif mapping[i] in 'ACGTacgt':
                alt = mapping[i].upper()
                self.base_counts[alt] += 1
                p = pow(10, -ord(quals[j]) / 10)
                self.base_probs[alt].append(1 - p)
                for b in other_nts[alt]:
                    self.base_probs[b].append(p / 3)
                i += 1
                j += 1
            elif mapping[i] in 'Nn':
                i += 1
                j += 1
            elif mapping[i] in '-+':
                result = indel_re.match(mapping, i + 1)
                length = int(mapping[result.start():result.end()])
                i = result.end() + length
        del(self.mpileup)

    def _is_valid_operand(self, other: object) -> bool:
        return type(self) == type(other) and \
            hasattr(other, 'chrom') and hasattr(other, 'pos')

    def __eq__(self, other: object) -> bool:
        if not self._is_valid_operand(other):
            return NotImplemented
        return (self.chrom, self.pos) == (other.chrom, other.pos)

    def __lt__(self, other: object) -> bool:
        if not self._is_valid_operand(other):
            return NotImplemented
        return (self.chrom, self.pos) < (other.chrom, other.pos)

    def __getitem__(self, k: str) -> int:
        try:
            return self.base_counts[k]
        except AttributeError:
            self._parse()
            return self[k]

    def __getattr__(self, name: str) -> Any:
        try:
            self._parse()
            if name not in self.__dict__:
                raise AttributeError
            return self.__dict__[name]
        except AttributeError:
            raise AttributeError(f'{name} is not an UnstrandedPileup attribute')

    def __add__(self, other: object) -> object:
        if self == other:
            obj = Empty()
            obj.__class__ = self.__class__
            obj.chrom, obj.pos, obj.ref = self.chrom, self.pos, self.ref
            obj.base_counts = {}
            obj.base_probs = {}
            for base in 'ACGT':
                obj.base_counts[base] = self[base] + other[base]
                obj.base_probs[base] = self.base_probs[base] + other.base_probs[base]
            return obj
        else:
            raise ValueError('UnstrandedPileup objects do not refer to the same position')

    def __radd__(self, other: object) -> object:
        if other == 0:
            return self
        return self.__add__(other)

    def depth(self) -> int:
        try:
            return sum(self.base_counts.values())
        except AttributeError:
            self._parse()
            return self.depth()

    def is_potential_edit(self) -> bool:
        try:
            return 0 < self[self.ref] < self.depth() >= args.depth
        except AttributeError:
            self._parse()
            return self.is_potential_edit()

    def a(self) -> np.ndarray:
        ''' unscaled alpha values for scipy.stats.dirichlet '''
        try:
            return np.array(list(
                (0.0 if k == self.ref else args.noise / 3) + (sum(v)/len(v) if v else 0.0)
                for k, v in self.base_probs.items()))
        except AttributeError:
            self._parse()
            return self.a()

    def x(self) -> np.ndarray:
        ''' quantile values for scipy.stats.dirichlet '''
        try:
            return np.array(list(
                sum(v)/len(v) if v else 0.0
                for k, v in self.base_probs.items()))
        except AttributeError:
            self._parse()
            return self.x()

    def __str__(self) -> str:
        try:
            return f'{self.chrom}\t{self.pos}\t{self.ref}\t' + \
                f'{self.base_counts["A"]}\t' + \
                f'{self.base_counts["C"]}\t' + \
                f'{self.base_counts["G"]}\t' + \
                f'{self.base_counts["T"]}'
        except AttributeError:
            self._parse()
            return self.__str__()


@total_ordering
class StrandedPileup(object):
    ''' A class for holding per-base stranded mpileup data '''

    def __init__(self, mpileup: str) -> None:
        self.chrom, pos, self.ref, *self.mpileup = mpileup.strip().split('\t')
        self.pos = int(pos)

    def _parse(self) -> None:
        self.base_counts = {
            True: {'A': 0, 'C': 0, 'G': 0, 'T': 0},
            False: {'A': 0, 'C': 0, 'G': 0, 'T': 0}}
        self.base_probs = {
            True: {'A': [], 'C': [], 'G': [], 'T': []},
            False: {'A': [], 'C': [], 'G': [], 'T': []}}
        _, mapping, quals, strand, *_ = self.mpileup
        strand = [True if s == '+' else False for s in strand.split(',')]
        i, j = 0, 0
        while i < len(mapping):
            if mapping[i] in '.,':
                self.base_counts[strand[j]][self.ref] += 1
                p = pow(10, -ord(quals[j]) / 10)
                self.base_probs[strand[j]][self.ref].append(1 - p)
                for b in other_nts[self.ref]:
                    self.base_probs[strand[j]][b].append(p / 3)
                i += 1
                j += 1
            elif mapping[i] in '<>*#':
                i += 1
                j += 1
            elif mapping[i] == '^':
                i += 2
            elif mapping[i] == '$':
                i += 1
            elif mapping[i] in 'ACGTacgt':
                alt = mapping[i].upper()
                self.base_counts[strand[j]][alt] += 1
                p = pow(10, -ord(quals[j]) / 10)
                self.base_probs[strand[j]][alt].append(1 - p)
                for b in other_nts[alt]:
                    self.base_probs[strand[j]][b].append(p / 3)
                i += 1
                j += 1
            elif mapping[i] in 'Nn':
                i += 1
                j += 1
            elif mapping[i] in '-+':
                result = indel_re.match(mapping, i + 1)
                length = int(mapping[result.start():result.end()])
                i = result.end() + length
        del(self.mpileup)

    def _is_valid_operand(self, other: object) -> bool:
        return type(self) == type(other) and \
            hasattr(other, 'chrom') and hasattr(other, 'pos')

    def __eq__(self, other: object) -> bool:
        if not self._is_valid_operand(other):
            return NotImplemented
        return (self.chrom, self.pos) == (other.chrom, other.pos)

    def __lt__(self, other: object) -> bool:
        if not self._is_valid_operand(other):
            return NotImplemented
        return (self.chrom, self.pos) < (other.chrom, other.pos)

    def __getitem__(self, ktuple: Tuple[str, bool]) -> int:
        base, strand = ktuple
        try:
            return self.base_counts[strand][base]
        except AttributeError:
            self._parse()
            return self[ktuple]

    def __getattr__(self, name: str) -> Any:
        try:
            self._parse()
            if name not in self.__dict__:
                raise AttributeError
            return self.__dict__[name]
        except AttributeError:
            raise AttributeError(f'{name} is not a StrandedPileup attribute')

    def __add__(self, other: object) -> object:
        if self == other:
            obj = Empty()
            obj.__class__ = self.__class__
            obj.chrom, obj.pos, obj.ref = self.chrom, self.pos, self.ref
            obj.base_counts = {True: {}, False: {}}
            obj.base_probs = {True: {}, False: {}}
            for strand in (True, False):
                for base in 'ACGT':
                    obj.base_counts[strand][base] = \
                        self[base, strand] + other[base, strand]
                    obj.base_probs[strand][base] = \
                        self.base_probs[strand][base] + other.base_probs[strand][base]
            return obj
        else:
            raise ValueError('StrandedPileup objects do not refer to the same position')

    def __radd__(self, other: object) -> object:
        if other == 0:
            return self
        return self.__add__(other)

    def depth(self, strand=None) -> int:
        try:
            if strand is not None:
                return sum(self.base_counts[strand].values())
            return sum(v2 for v in self.base_counts.values() for v2 in v.values())
        except AttributeError:
            self._parse()
            return self.depth(strand)

    def is_potential_edit(self, strand: bool) -> bool:
        try:
            return 0 < self[self.ref, strand] < self.depth(strand) \
                >= args.depth >= self.depth(not strand) * 0.01
        except AttributeError:
            self._parse()
            return self.is_potential_edit(strand)

    def a(self, strand: bool) -> np.ndarray:
        ''' unscaled alpha values for scipy.stats.dirichlet '''
        try:
            return np.array(list(
                (0.0 if k == self.ref else args.noise / 3) + (sum(v)/len(v) if v else 0.0)
                for k, v in self.base_probs[strand].items()))
        except AttributeError:
            self._parse()
            return self.a(strand)

    def x(self, strand: bool) -> np.ndarray:
        ''' quantile values for scipy.stats.dirichlet '''
        try:
            return np.array(list(
                sum(v)/len(v) if v else 0.0
                for k, v in self.base_probs[strand].items()))
        except AttributeError:
            self._parse()
            return self.x(strand)

    def __str__(self) -> str:
        try:
            return f'{self.chrom}\t{self.pos}\t{self.ref}\t' + \
                f'{self.base_counts[True]["A"]}:{self.base_counts[False]["A"]}\t' + \
                f'{self.base_counts[True]["C"]}:{self.base_counts[False]["C"]}\t' + \
                f'{self.base_counts[True]["G"]}:{self.base_counts[False]["G"]}\t' + \
                f'{self.base_counts[True]["T"]}:{self.base_counts[False]["T"]}'
        except AttributeError:
            self._parse()
            return self.__str__()


# Functions ###################################################################


def shared_elements(*inputs: Iterator) -> Iterator[list]:
    ''' Aligns an arbitrary number of sorted iterables and yields matching
    groups '''
    End = object()
    inputs = [chain(i, [End]) for i in inputs]
    vals = [next(i) for i in inputs]
    while not any(v is End for v in vals):
        low = min(vals)
        if all(v == low for v in vals):
            yield vals
            vals = [next(i) for i in inputs]
        else:
            vals = [next(i) if v == low else v for i, v in zip(inputs, vals)]


def align_elements(*inputs: Iterator, missing: Any=None) -> Iterator[tuple]:
    ''' Aligns an arbitrary number of sorted iterables and yields groups,
    filling missing entries for individual iterables with `missing` '''
    End = object()
    inputs = [chain(i, [End]) for i in inputs]
    vals = [next(i) for i in inputs]
    while not all(v is End for v in vals):
        low = min(v for v in vals if v is not End)
        yield tuple(v if v == low else missing for v in vals)
        vals = [next(i) if v == low else v for i, v in zip(inputs, vals)]


def differential_stranded(test_pileups: Tuple[StrandedPileup], ctrl_pileups: Tuple[StrandedPileup]) -> bool:
    significant = False
    to_test = []
    test = sum(test_pileups)
    ctrl = sum(ctrl_pileups)
    for strand in (True, False):
        if test.is_potential_edit(strand) and ctrl.depth(strand) >= args.depth:
            if args.edit:
                if test[args.edit[1], strand] >= args.alt_depth and \
                        sum(t[args.edit[1], strand] > 0 for t in test_pileups) >= args.replicates:
                    to_test.append((args.edit[1], strand))
            else:
                to_test += [
                    (alt, strand) for alt in other_nts[test.ref] if
                    (test[alt, strand] >= args.alt_depth and
                        sum(t[alt, strand] > 0 for t in test_pileups) >= args.replicates)]
    for alt, strand in to_test:
        try:
            scale = test.depth(strand)
            test_x = test.x(strand)
            test_a = test.a(strand)
            Z = log10(
                dirichlet.pdf(test_x, test_a * scale) / \
                dirichlet.pdf(test_x, background_probs[test.ref] * scale))
            Z *= sum(t[alt, strand] > 0 for t in test_pileups) / len(test_pileups)
            if Z > args.z_score:
                scale = min(test.depth(strand), ctrl.depth(strand))
                test_a = test_a * scale
                ctrl_x = ctrl.x(strand)
                ctrl_a = ctrl.a(strand) * scale
                Z = log10(
                    (dirichlet.pdf(test_x, test_a) * dirichlet.pdf(ctrl_x, ctrl_a)) / \
                    (dirichlet.pdf(ctrl_x, test_a) * dirichlet.pdf(test_x, ctrl_a)))
                Z *= sum(t[alt, strand] > 0 for t in test_pileups) / len(test_pileups)
                if Z > args.z_score and \
                        test[alt, strand] / test.depth(strand) > \
                        ctrl[alt, strand] / ctrl.depth(strand):
                    print(
                        f'{test.chrom}\t'
                        f'{test.pos - 1}\t'  # BED6 is 0-based
                        f'{test.pos}\t'
                        f'{test.ref}{alt}\t'
                        f'{Z:.2f}\t'
                        f'{"+" if strand else "-"}',
                        file=args.output, flush=True)
                    significant = True
        except ValueError:
            continue
    return significant


def differential_unstranded(test_pileups: Tuple[UnstrandedPileup], ctrl_pileups: Tuple[UnstrandedPileup]) -> bool:
    significant = False
    to_test = []
    test = sum(test_pileups)
    ctrl = sum(ctrl_pileups)
    if test.is_potential_edit() and ctrl.depth() >= args.depth:
        if args.edit:
            if test[args.edit[1]] >= args.alt_depth and \
                    sum(t[args.edit[1]] > 0 for t in test_pileups) >= args.replicates:
                to_test.append(args.edit[1])
        else:
            to_test += [
                alt for alt in other_nts[test.ref] if
                (test[alt] >= args.alt_depth and
                    sum(t[alt] > 0 for t in test_pileups) >= args.replicates)]
    for alt in to_test:
        try:
            scale = test.depth()
            test_x = test.x()
            test_a = test.a()
            Z = log10(
                dirichlet.pdf(test_x, test_a * scale) / \
                dirichlet.pdf(test_x, background_probs[test.ref] * scale))
            Z *= sum(t[alt] > 0 for t in test_pileups) / len(test_pileups)
            if Z > args.z_score:
                scale = min(test.depth(), ctrl.depth())
                test_a = test_a * scale
                ctrl_x = ctrl.x()
                ctrl_a = ctrl.a() * scale
                Z = log10(
                    (dirichlet.pdf(test_x, test_a) * dirichlet.pdf(ctrl_x, ctrl_a)) / \
                    (dirichlet.pdf(ctrl_x, test_a) * dirichlet.pdf(test_x, ctrl_a)))
                Z *= sum(t[alt] > 0 for t in test_pileups) / len(test_pileups)
                if Z > args.z_score and \
                        test[alt] / test.depth() > ctrl[alt] / ctrl.depth():
                    print(
                        f'{test.chrom}\t'
                        f'{test.pos - 1}\t'  # BED6 is 0-based
                        f'{test.pos}\t'
                        f'{test.ref}{alt}\t'
                        f'{Z:.2f}\t'
                        f'.',
                        file=args.output, flush=True)
                    significant = True
        except ValueError:
            continue
    return significant


def detect_stranded(test_pileups: Tuple[StrandedPileup]) -> bool:
    significant = False
    to_test = []
    test = sum(test_pileups)
    for strand in (True, False):
        if test.is_potential_edit(strand):
            if args.edit:
                if test[args.edit[1], strand] >= args.alt_depth and \
                        sum(t[args.edit[1], strand] > 0 for t in test_pileups) >= args.replicates:
                    to_test.append((args.edit[1], strand))
            else:
                to_test += [
                    (alt, strand) for alt in other_nts[test.ref] if
                    (test[alt, strand] >= args.alt_depth and
                        sum(t[alt, strand] > 0 for t in test_pileups) >= args.replicates)]
    for alt, strand in to_test:
        try:
            scale = test.depth(strand)
            test_x = test.x(strand)
            test_a = test.a(strand)
            Z = log10(
                dirichlet.pdf(test_x, test_a * scale) / \
                dirichlet.pdf(test_x, background_probs[test.ref] * scale))
            Z *= sum(t[alt, strand] > 0 for t in test_pileups) / len(test_pileups)
            if Z > args.z_score:
                print(
                    f'{test.chrom}\t'
                    f'{test.pos - 1}\t'  # BED6 is 0-based
                    f'{test.pos}\t'
                    f'{test.ref}{alt}\t'
                    f'{Z:.2f}\t'
                    f'{"+" if strand else "-"}',
                    file=args.output, flush=True)
                significant = True
        except ValueError:
            continue
    return significant


def detect_unstranded(test_pileups: Tuple[UnstrandedPileup]) -> bool:
    significant = False
    test = sum(test_pileups)
    to_test = []
    if test.is_potential_edit():
        if args.edit:
            if test[args.edit[1]] >= args.alt_depth and \
                    sum(t[args.edit[1]] > 0 for t in test_pileups) >= args.replicates:
                to_test.append(args.edit[1])
        else:
            to_test += [
                alt for alt in other_nts[test.ref] if
                (test[alt] >= args.alt_depth and
                    sum(t[alt] > 0 for t in test_pileups) >= args.replicates)]
        for alt in to_test:
            try:
                scale = test.depth()
                test_x = test.x()
                test_a = test.a()
                Z = log10(
                    dirichlet.pdf(test_x, test_a * scale) / \
                    dirichlet.pdf(test_x, background_probs[test.ref] * scale))
                Z *= sum(t[alt] > 0 for t in test_pileups) / len(test_pileups)
                if Z > args.z_score:
                    print(
                        f'{test.chrom}\t'
                        f'{test.pos - 1}\t'  # BED6 is 0-based
                        f'{test.pos}\t'
                        f'{test.ref}{alt}\t'
                        f'{Z:.2f}\t'
                        f'.',
                        file=args.output, flush=True)
                    significant = True
            except ValueError:
                continue
    return significant


###############################################################################


if __name__ == '__main__':

    # Parse commandline args ##################################################

    parser = ArgumentParser(
        description='edIted: statistical comparison of RNA editing',
        prog='edIted',
        epilog=f'%(prog)s v{__version__}_{__stamp__} ({__status__})')
    parser.add_argument(
        '-t', '--test', nargs='+', required=True,
        help='test/treated mpileup file(s), with multiple files treated as \
        biological replicates')
    parser.add_argument(
        '-c', '--control', nargs='+',
        help='optional control/untreated mpileup file(s), which will make \
        edIted run a differential editing analysis rather than simply  \
        identifing edited bases within the test dataset')
    parser.add_argument(
        '-s', '--stranded', action='store_true',
        help='honour stranding information within the mpileup inputs (default \
        behaviour ignores read stranding)')
    parser.add_argument(
        '-o', '--output', type=FileType('w'), default=stdout,
        help='write output to this file instead of piping to stdout')
    parser.add_argument(
        '-e', '--edit', type=str, default='',
        help='detect only one specific type of editing e.g. "AG"')
    parser.add_argument(
        '-n', '--noise', type=float, default=0.01,
        help='noise to spread between alt base probabilities for modelling \
        sequencing-independent error sources in differential editing testing \
        (default %(default)s)')
    parser.add_argument(
        '-z', '--z_score', type=float, default=1.96,
        help='Z score for discriminating the goodness of fit of Dirichlet \
        models of nucleotide frequencies (default %(default)s)')
    parser.add_argument(
        '-d', '--depth', type=int, default=4,
        help='minimum required coverage for a base to be considered (default \
        %(default)s)')
    parser.add_argument(
        '-a', '--alt_depth', type=int, default=2,
        help='minimum required alt count for ref-to-alt editing to be \
        considered (default %(default)s)')
    parser.add_argument(
        '-r', '--replicates', type=int, default=1,
        help='where replicates are given, the minimum number of replicates in \
        which editing must be found to be considered (default %(default)s)')
    # parser.add_argument(
    #     '-b', '--blacklist', nargs='+',
    #     help='regions (BED format) to exclude from analyses')
    # parser.add_argument(
    #     '-v', '--vcf', nargs='+',
    #     help='known variations (VCF format) to exclude from analyses')
    parser.add_argument(
        '-q', '--quiet', action='store_true',
        help='silence progress reporting')
    args = parser.parse_args()

    args.edit = args.edit.upper()
    if not all(c in 'ACGT' for c in args.edit):
        raise ValueError('--edit nucleotides must be A, C, G, or T')

    # Setup logging system ####################################################

    logger = logging.getLogger()
    logstream = logging.StreamHandler()
    logstream.setFormatter(logging.Formatter(
        '%(asctime)s\t%(message)s', '%y%m%d %H:%M:%S'))
    logging.basicConfig(
        level=logging.ERROR if args.quiet else logging.INFO,
        handlers=[logstream])
    logger.info(f'edIted v{__version__}_{__stamp__} ({__status__})')

    ###########################################################################

    logger.info('Determining background error rates')
    alt_freq = {k: Counter({'A': 0, 'C': 0, 'G': 0, 'T': 0}) for k in 'ACGT'}
    aligned_pileups = shared_elements(
        *((UnstrandedPileup(l) for l in gzip.open(f, 'rt')) for f in args.test))
    i = 0
    while i < 2_500_000:
        try:
            base = sum(next(aligned_pileups))
            if base.ref != 'N':
                alt_freq[base.ref].update(base.base_counts)
                i += 1
        except StopIteration:
            break
    background_probs = {}
    for base in 'ACGT':
        total = sum(alt_freq[base].values())
        background_probs[base] = np.array(list({
            k: v / total
            for k, v in alt_freq[base].items()}.values()))
    del(aligned_pileups, alt_freq, base, i, total)

    ###########################################################################

    parser = StrandedPileup if args.stranded else UnstrandedPileup
    bases_significant, bases_scanned = 0, 0

    if args.control:
    # Differential analysis pipeline

        if len(args.test) == 1 == len(args.control):
            aligned_pileups = shared_elements(
                (parser(l) for l in gzip.open(args.test[0], 'rt')),
                (parser(l) for l in gzip.open(args.control[0], 'rt')))
        else:
            aligned_pileups = align_elements(
                *((parser(l) for l in gzip.open(f, 'rt')) for f in args.test),
                *((parser(l) for l in gzip.open(f, 'rt')) for f in args.control))

        if args.stranded:
            logger.info('Scanning for strand-specific differential base modification')
            print('track name=edIted description="Stranded differential RNA modifications" useScore=1',
                file=args.output, flush=True)
        else:
            logger.info('Scanning for differential base modification')
            print('track name=edIted description="Unstranded differential RNA modifications" useScore=1',
                file=args.output, flush=True)

        for base_pileups in aligned_pileups:
            if len(args.test) == 1 == len(args.control):
                test_pileups, ctrl_pileups = base_pileups
            else:
                test_pileups = tuple(i for i in base_pileups[:len(args.test)] if i is not None)
                ctrl_pileups = tuple(i for i in base_pileups[len(args.test):] if i is not None)
                if len(test_pileups) < args.replicates or not ctrl_pileups:
                    continue
            if (args.edit and test_pileups[0].ref != args.edit[0]) or \
                    test_pileups[0].ref not in 'ACGT':
                continue
            if args.stranded:
                if differential_stranded(test_pileups, ctrl_pileups):
                    bases_significant += 1
            elif differential_unstranded(test_pileups, ctrl_pileups):
                bases_significant += 1
            bases_scanned += 1

    else:
    # Detect modifications only

        if len(args.test) == 1:
            aligned_pileups = ((parser(l),) for l in gzip.open(args.test[0], 'rt'))
        else:
            aligned_pileups = align_elements(
                *((parser(l) for l in gzip.open(f, 'rt')) for f in args.test))

        if args.stranded:
            logger.info('Scanning for strand-specific base modifications')
            print('track name=edIted description="Stranded RNA modifications" useScore=1',
                file=args.output, flush=True)
        else:
            logger.info('Scanning for base modifications')
            print('track name=edIted description="Unstranded RNA modifications" useScore=1',
                file=args.output, flush=True)

        for test_pileups in aligned_pileups:
            if len(args.test) > 1:
                test_pileups = tuple(i for i in test_pileups[:len(args.test)] if i is not None)
                if len(test_pileups) < args.replicates:
                    continue
            if (args.edit and test_pileups[0].ref != args.edit[0]) or \
                    test_pileups[0].ref not in 'ACGT':
                continue
            if args.stranded:
                if detect_stranded(test_pileups):
                    bases_significant += 1
            elif detect_unstranded(test_pileups):
                bases_significant += 1
            bases_scanned += 1

    ###########################################################################

    logger.info(f'{bases_significant} significant bases in {bases_scanned}')
    logging.info('Finished')
