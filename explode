#!/usr/bin/env python

# GY190923

''' explode: split FASTA/Q records to new files '''


from argparse import ArgumentParser, FileType, SUPPRESS
from itertools import cycle
from os import path
from signal import signal, SIGPIPE, SIG_DFL
from string import ascii_letters, digits
from sys import stdin, stdout
from typing import Iterator, NamedTuple, TextIO

signal(SIGPIPE, SIG_DFL)  # Gracefully handle downstream PIPE closure


# Globals #####################################################################


LEGAL_CHARS = "-_" + ascii_letters + digits


# Classes #####################################################################


class SeqRecord(NamedTuple):
    ''' A class for holding sequence data '''
    seqid: str
    seq: str
    quals: str = ''

    def __len__(self):
        return len(self.seq)

    def print(self, wrap: int=0, fileobj: TextIO=stdout) -> None:
        ''' Print a sequence as FASTA/Q '''
        if self.quals:
            print(f'@{self.seqid}\n{self.seq}\n+\n{self.quals}', file=fileobj)
        elif wrap:
            print(f'>{self.seqid}', file=fileobj)
            for g in grouper(self.seq, wrap):
                print(g, file=fileobj)
        else:
            print(f'>{self.seqid}\n{self.seq}', file=fileobj)


class MultiReader(object):
    ''' A class for reading FASTA/Q records '''

    def __init__(self, inputstream: TextIO, replaceU: bool=False):
        self._fileobj = inputstream
        self._buffer = ' '
        self.replaceU = replaceU

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        pass

    def __iter__(self):
        return self

    def __next__(self) -> SeqRecord:
        while self._buffer and self._buffer[0] not in ('>', '@'):
            self._buffer = self._fileobj.readline()
        if not self._buffer:
            raise StopIteration
        if self._buffer.startswith('>'):
            seqid = self._buffer[1:].strip('\r\n')
            self._buffer = self._fileobj.readline()
            seqlines = []
            while self._buffer and self._buffer[0] not in ('>', '@'):
                seqlines.append(self._buffer.strip('\r\n'))
                self._buffer = self._fileobj.readline()
            if not (seq := ''.join(seqlines)):
                raise EOFError
            seq = seq.upper()
            if self.replaceU:
                seq = seq.replace('U', 'T')
            return SeqRecord(seqid, seq)
        else:  # self._buffer.startswith('@')
            seqid = self._buffer[1:].strip('\r\n')
            seq = self._fileobj.readline().strip('\r\n')
            self._fileobj.readline()
            quals = self._fileobj.readline().strip('\r\n')
            self._buffer = self._fileobj.readline()
            if not (seq and quals):
                raise EOFError
            seq = seq.upper()
            if self.replaceU:
                seq = seq.replace('U', 'T')
            return SeqRecord(seqid, seq, quals)


# Functions ###################################################################


def grouper(iterable: Iterator, k: int) -> Iterator[Iterator]:
    ''' Yield a memory-mapped `iterable` in chunks of `k`
    !!! If iterable % k != 0 the length of the last chunk will be <k !!! '''
    for i in range(len(iterable) // k + (1 if len(iterable) % k else 0)):
        yield iterable[i*k:i*k+k]


def sanitise(s: str, sub: str='_') -> str:
    ''' Sanitise a string for file names '''
    return ''.join(c if c in LEGAL_CHARS else sub for c in s)


###############################################################################


if __name__ == '__main__':

    parser = ArgumentParser(
        description='Split FASTA/Q records to new files',
        argument_default=SUPPRESS)
    parser.add_argument(
        'input', nargs='*', type=FileType('r'), default=[stdin],
        help='Input file(s) (use "-" or leave blank for stdin)')
    parser.add_argument(
        '-c', '--chunks', type=int,
        help='Split the file into `c` chunks')
    parser.add_argument(
        '--dir', default='',
        help='Output to (an existing) directory')
    parser.add_argument(
        '--prefix', default='',
        help='Prefix file names with this string')
    parser.add_argument(
        '-w', '--wrap', nargs='?', type=int, const=80, default=0,
        help='Wrap lines at `w` when outputting FASTA (%(const)s \
        when supplied alone)')

    args = parser.parse_args()

    if 'chunks' not in args:
        for f in args.input:
            with MultiReader(f) as F:
                for record in F:
                    p = path.join(
                        args.dir,
                        f'{args.prefix}' \
                        f'{sanitise(record.seqid.split()[0])}' \
                        f'.{"fq" if record.quals else "fa"}')
                    print(p)
                    with open(p, 'w') as outfile:
                        record.print(args.wrap, outfile)
            f.close()

    else:
        out_files = [open(path.join(args.dir, args.prefix + f'{i}'), 'w')
            for i in range(1, args.chunks + 1)]
        file_loop = cycle(out_files)
        for f in args.input:
            with MultiReader(f) as F:
                for record in F:
                    record.print(args.wrap, next(file_loop))
            f.close()
        for f in out_files:
            f.close()
